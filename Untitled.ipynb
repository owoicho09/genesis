{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "776c9ed4-aff1-4791-8833-6aea15dbc349",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping googlesearch as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/Nv7-GitHub/googlesearch\n",
      "  Cloning https://github.com/Nv7-GitHub/googlesearch to c:\\users\\hp\\appdata\\local\\temp\\pip-req-build-2zkte57d\n",
      "  Resolved https://github.com/Nv7-GitHub/googlesearch to commit fbb1f3a935f96d87da99f587da977ebe2c8883ae\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4>=4.9 in c:\\users\\hp\\desktop\\genesis.ai\\env\\lib\\site-packages (from googlesearch-python==1.3.0) (4.13.4)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\hp\\desktop\\genesis.ai\\env\\lib\\site-packages (from googlesearch-python==1.3.0) (2.32.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hp\\desktop\\genesis.ai\\env\\lib\\site-packages (from beautifulsoup4>=4.9->googlesearch-python==1.3.0) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\hp\\desktop\\genesis.ai\\env\\lib\\site-packages (from beautifulsoup4>=4.9->googlesearch-python==1.3.0) (4.14.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hp\\desktop\\genesis.ai\\env\\lib\\site-packages (from requests>=2.20->googlesearch-python==1.3.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\desktop\\genesis.ai\\env\\lib\\site-packages (from requests>=2.20->googlesearch-python==1.3.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\desktop\\genesis.ai\\env\\lib\\site-packages (from requests>=2.20->googlesearch-python==1.3.0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\desktop\\genesis.ai\\env\\lib\\site-packages (from requests>=2.20->googlesearch-python==1.3.0) (2025.4.26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/Nv7-GitHub/googlesearch 'C:\\Users\\HP\\AppData\\Local\\Temp\\pip-req-build-2zkte57d'\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'googlesearch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m get_ipython().system(\u001b[33m'\u001b[39m\u001b[33mpip uninstall googlesearch -y\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m get_ipython().system(\u001b[33m'\u001b[39m\u001b[33mpip install git+https://github.com/Nv7-GitHub/googlesearch\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgooglesearch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m search\n\u001b[32m      7\u001b[39m results = search(\u001b[33m\"\u001b[39m\u001b[33mfitness coach site:about.me\u001b[39m\u001b[33m\"\u001b[39m, num_results=\u001b[32m5\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'googlesearch'"
     ]
    }
   ],
   "source": [
    "!pip uninstall googlesearch -y\n",
    "\n",
    "!pip install git+https://github.com/Nv7-GitHub/googlesearch\n",
    "\n",
    "from googlesearch import search\n",
    "\n",
    "results = search(\"fitness coach site:about.me\", num_results=5)\n",
    "for url in results:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26763b2e-1aed-4f87-b174-0ab2b448cee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from googlesearch import search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467ace3-22fe-4a98-b45d-8b8e8aeff1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "EMAIL_REGEX = r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\"\n",
    "\n",
    "query = '\"fitness coach\" \"@gmail.com\" site:linkedin.com'\n",
    "urls = search(query, num_results=50)\n",
    "\n",
    "emails_found = []\n",
    "\n",
    "for url in urls:\n",
    "    try:\n",
    "        res = requests.get(url, timeout=10)\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        emails = re.findall(EMAIL_REGEX, text)\n",
    "        for email in set(emails):\n",
    "            print(f\"üß† {email}\")\n",
    "            emails_found.append(email)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {url} ‚Äî {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e3c01c-8a68-4979-a13f-78fa0f6061e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleDorkScraper:\n",
    "    def __init__(self, niche, limit=20):\n",
    "        self.niche = niche\n",
    "        self.limit = limit\n",
    "        self.scraped_leads = []\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"\\nüîç Scraping Google for: {self.niche}\")\n",
    "        for dork in DEFAULT_DORKS:\n",
    "            query = dork.format(niche=self.niche)\n",
    "            print(f\"\\nüåê Query: {query}\")\n",
    "\n",
    "            try:\n",
    "                urls = search(query, num_results=self.limit)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Google search failed: {e}\")\n",
    "                continue\n",
    "\n",
    "            for url in urls:\n",
    "                print(f\"‚û°Ô∏è Visiting: {url}\")\n",
    "                try:\n",
    "                    res = requests.get(url, headers=HEADERS, timeout=10)\n",
    "                    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "                    text = soup.get_text()\n",
    "                    emails = re.findall(EMAIL_REGEX, text)\n",
    "                    for email in set(emails):\n",
    "                        self.save_lead(email, url)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Error visiting {url}: {e}\")\n",
    "                time.sleep(5)  # delay to avoid being flagged\n",
    "\n",
    "    def save_lead(self, email, source_url):\n",
    "        username = email.split('@')[0]\n",
    "        lead, created = Lead.objects.get_or_create(\n",
    "            email=email,\n",
    "            defaults={\n",
    "                'username': username,\n",
    "                'niche': self.niche,\n",
    "                'source_url': source_url,\n",
    "                'status': 'scraped'\n",
    "            }\n",
    "        )\n",
    "        if created:\n",
    "            print(f\"‚úÖ Saved: {email}\")\n",
    "            self.scraped_leads.append({\n",
    "                'username': username,\n",
    "                'email': email,\n",
    "                'niche': self.niche,\n",
    "                'source_url': source_url\n",
    "            })\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Already exists: {email}\")\n",
    "\n",
    "    def export_csv(self, path):\n",
    "        if not self.scraped_leads:\n",
    "            print(\"‚ö†Ô∏è No new leads to export.\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            with open(path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=['username', 'email', 'niche', 'source_url'])\n",
    "                writer.writeheader()\n",
    "                for lead in self.scraped_leads:\n",
    "                    writer.writerow(lead)\n",
    "            print(f\"üìÅ Exported leads to {path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to export CSV: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
